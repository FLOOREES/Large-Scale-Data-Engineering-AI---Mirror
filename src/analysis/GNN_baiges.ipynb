{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0544618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/libpyg.so, 0x0006): Symbol not found: __ZN3c1010Dispatcher17runRecordFunctionERN2at14RecordFunctionENSt3__117reference_wrapperIKNS_14FunctionSchemaEEENS_11DispatchKeyE\n",
      "  Referenced from: <D39B31F4-BCFB-3005-A82F-3F010BF36435> /Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/libpyg.so\n",
      "  Expected in:     <6B8AC17B-04CC-36D0-BD01-780381EFB0CC> /Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: dlopen(/Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch_scatter/_version_cpu.so, 0x0006): Symbol not found: __ZN5torch3jit17parseSchemaOrNameERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE\n",
      "  Referenced from: <B61D6BDA-DF58-31FC-B7D3-5F1A6FBC154B> /Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch_scatter/_version_cpu.so\n",
      "  Expected in:     <6B8AC17B-04CC-36D0-BD01-780381EFB0CC> /Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch_sparse/_version_cpu.so, 0x0006): Symbol not found: __ZN5torch3jit17parseSchemaOrNameERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE\n",
      "  Referenced from: <7A612FE8-A2BB-3D1C-A452-5845B6B47F4D> /Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch_sparse/_version_cpu.so\n",
      "  Expected in:     <6B8AC17B-04CC-36D0-BD01-780381EFB0CC> /Users/rogerbaigess/Desktop/IA/3r/BDA/large-scale-data-engineering-ai/.venv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1\n",
      "PyG version: 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import to_undirected\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "import rdflib\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "try:\n",
    "    import torch_geometric\n",
    "    print(f\"PyG version: {torch_geometric.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch Geometric not found. Please install it.\")\n",
    "\n",
    "PROJ = Namespace(\"http://example.com/catalonia-ontology/\")\n",
    "\n",
    "# --- Configuration ---\n",
    "KG_PATH = \"../../data/exploitation/knowledge_graph.ttl\"\n",
    "EMBEDDING_DIM = 64 # Final dimension of the node embeddings\n",
    "HIDDEN_CHANNELS = 128 # Number of channels in the hidden GNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64b89cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full Knowledge Graph from: ../../data/exploitation/knowledge_graph.ttl\n",
      "Graph loaded successfully with 180513 triples.\n",
      "\n",
      "--- Preparing data for PyTorch Geometric ---\n",
      "Mapped 29332 unique entity nodes to integer indices.\n",
      "Created undirected edge_index tensor with shape: torch.Size([2, 150632])\n",
      "\n",
      "Extracting numerical features for each node...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Node Features: 100%|██████████| 29332/29332 [00:01<00:00, 16270.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filled NaN values with 0.\n",
      "Created features DataFrame with shape: (29332, 4)\n",
      "Sample of extracted features before scaling:\n",
      "       idescat_value   annual_rent  annual_income  annual_contracts\n",
      "count        29332.0  29332.000000        29332.0      29332.000000\n",
      "mean             0.0    250.394189            0.0        124.615096\n",
      "std              0.0    282.898497            0.0       1935.808171\n",
      "min              0.0      0.000000            0.0          0.000000\n",
      "25%              0.0      0.000000            0.0          0.000000\n",
      "50%              0.0      0.000000            0.0          0.000000\n",
      "75%              0.0    456.335000            0.0         14.000000\n",
      "max              0.0   1649.991000            0.0     165779.000000\n",
      "\n",
      "Normalizing node features...\n",
      "Created node feature tensor 'x' with shape: torch.Size([29332, 4])\n",
      "\n",
      "PyG Data object created successfully:\n",
      "Data(x=[29332, 4], edge_index=[2, 150632])\n"
     ]
    }
   ],
   "source": [
    "# --- Load the full graph ---\n",
    "print(f\"Loading full Knowledge Graph from: {KG_PATH}\")\n",
    "g = Graph()\n",
    "g.parse(KG_PATH, format=\"turtle\")\n",
    "print(f\"Graph loaded successfully with {len(g)} triples.\")\n",
    "\n",
    "# --- Prepare data structures for PyG ---\n",
    "print(\"\\n--- Preparing data for PyTorch Geometric ---\")\n",
    "\n",
    "# 1. Map all unique entity URIs to integer indices\n",
    "all_uris = sorted([node for node in set(g.subjects()).union(set(g.objects())) if isinstance(node, rdflib.URIRef)])\n",
    "node_to_idx = {node: i for i, node in enumerate(all_uris)}\n",
    "idx_to_node = {i: node for i, node in enumerate(all_uris)}\n",
    "num_nodes = len(all_uris)\n",
    "print(f\"Mapped {num_nodes} unique entity nodes to integer indices.\")\n",
    "\n",
    "# 2. Create the edge index tensor\n",
    "edge_list = []\n",
    "for s, p, o in g:\n",
    "    if isinstance(s, rdflib.URIRef) and isinstance(o, rdflib.URIRef):\n",
    "        s_idx, o_idx = node_to_idx.get(s), node_to_idx.get(o)\n",
    "        if s_idx is not None and o_idx is not None:\n",
    "            edge_list.append([s_idx, o_idx])\n",
    "\n",
    "edge_index = to_undirected(torch.tensor(edge_list, dtype=torch.long).t())\n",
    "print(f\"Created undirected edge_index tensor with shape: {edge_index.shape}\")\n",
    "\n",
    "# 3. Create Node Features (the 'x' matrix) from literals\n",
    "print(\"\\nExtracting numerical features for each node...\")\n",
    "features_df = pd.DataFrame(index=range(num_nodes))\n",
    "\n",
    "feature_properties = {\n",
    "    PROJ.hasValue: 'idescat_value',\n",
    "    PROJ.avgMonthlyRent: 'annual_rent',\n",
    "    PROJ.householdIncome: 'annual_income',\n",
    "    PROJ.totalContracts: 'annual_contracts'\n",
    "}\n",
    "\n",
    "for feat_name in feature_properties.values():\n",
    "    features_df[feat_name] = np.nan\n",
    "\n",
    "for i in tqdm(range(num_nodes), desc=\"Extracting Node Features\"):\n",
    "    node_uri = idx_to_node[i]\n",
    "    for p, o in g.predicate_objects(subject=node_uri):\n",
    "        if p in feature_properties:\n",
    "            feat_name = feature_properties[p]\n",
    "            try:\n",
    "                features_df.loc[i, feat_name] = float(o)\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "\n",
    "# --- KEY FIX: Robustly fill NaN values with 0 ---\n",
    "# Using fillna(0) is safer than fillna(mean()) when some columns might be all NaN.\n",
    "features_df = features_df.fillna(0)\n",
    "print(\"\\nFilled NaN values with 0.\")\n",
    "# -----------------------------------------------\n",
    "\n",
    "print(f\"Created features DataFrame with shape: {features_df.shape}\")\n",
    "print(\"Sample of extracted features before scaling:\")\n",
    "print(features_df.describe())\n",
    "\n",
    "# 4. Normalize features\n",
    "print(\"\\nNormalizing node features...\")\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_df)\n",
    "x = torch.tensor(features_scaled, dtype=torch.float)\n",
    "print(f\"Created node feature tensor 'x' with shape: {x.shape}\")\n",
    "\n",
    "# 5. Create the final PyG Data object\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(\"\\nPyG Data object created successfully:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ba662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Manually Splitting Edges for Link Prediction ---\n",
      "Split positive edges: Train=120506, Val=15063, Test=15063\n",
      "Generating negative samples for each split...\n",
      "\n",
      "Data split and labeled successfully:\n",
      "\n",
      "--- Training Data ---\n",
      "Data(x=[29332, 4], edge_index=[2, 120506], edge_label_index=[2, 241012], edge_label=[241012])\n",
      "Edge labels shape: torch.Size([241012])\n",
      "Edge label index shape: torch.Size([2, 241012])\n",
      "\n",
      "--- Validation Data ---\n",
      "Data(x=[29332, 4], edge_index=[2, 120506], edge_label_index=[2, 30126], edge_label=[30126])\n",
      "Edge labels shape: torch.Size([30126])\n",
      "Edge label index shape: torch.Size([2, 30126])\n",
      "\n",
      "--- Testing Data ---\n",
      "Data(x=[29332, 4], edge_index=[2, 120506], edge_label_index=[2, 30126], edge_label=[30126])\n",
      "Edge labels shape: torch.Size([30126])\n",
      "Edge label index shape: torch.Size([2, 30126])\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Manual Edge Split for Link Prediction\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "print(\"\\n--- Manually Splitting Edges for Link Prediction ---\")\n",
    "\n",
    "# 1. Get all positive edges from the original graph\n",
    "num_nodes = data.num_nodes\n",
    "all_pos_edges = data.edge_index\n",
    "\n",
    "# 2. Split positive edges into train, validation, and test sets\n",
    "num_total_pos_edges = all_pos_edges.size(1)\n",
    "perm = torch.randperm(num_total_pos_edges) # Shuffle the edges\n",
    "\n",
    "# Define split sizes\n",
    "num_val = int(num_total_pos_edges * 0.1)\n",
    "num_test = int(num_total_pos_edges * 0.1)\n",
    "num_train = num_total_pos_edges - num_val - num_test\n",
    "\n",
    "# Assign edges to splits\n",
    "train_pos_edges = all_pos_edges[:, perm[:num_train]]\n",
    "val_pos_edges = all_pos_edges[:, perm[num_train : num_train + num_val]]\n",
    "test_pos_edges = all_pos_edges[:, perm[num_train + num_val:]]\n",
    "\n",
    "print(f\"Split positive edges: Train={train_pos_edges.size(1)}, Val={val_pos_edges.size(1)}, Test={test_pos_edges.size(1)}\")\n",
    "\n",
    "# 3. Create the training graph (IMPORTANT: it should contain only the training edges for message passing)\n",
    "# This prevents data leakage from validation/test edges into the training embeddings.\n",
    "train_data = Data(x=data.x, edge_index=train_pos_edges)\n",
    "val_data = Data(x=data.x, edge_index=train_pos_edges) # Val and Test also use train_pos_edges for message passing\n",
    "test_data = Data(x=data.x, edge_index=train_pos_edges)\n",
    "\n",
    "\n",
    "# 4. Generate negative edges and labels for each split\n",
    "print(\"Generating negative samples for each split...\")\n",
    "\n",
    "# For the training set\n",
    "train_neg_edges = negative_sampling(\n",
    "    edge_index=all_pos_edges, # Sample from all edges to avoid sampling validation/test positives\n",
    "    num_nodes=num_nodes,\n",
    "    num_neg_samples=train_pos_edges.size(1) # Match number of positive samples\n",
    ")\n",
    "train_data.edge_label_index = torch.cat([train_pos_edges, train_neg_edges], dim=-1)\n",
    "train_data.edge_label = torch.cat([torch.ones(train_pos_edges.size(1)), torch.zeros(train_neg_edges.size(1))], dim=0)\n",
    "\n",
    "# For the validation set\n",
    "val_neg_edges = negative_sampling(\n",
    "    edge_index=all_pos_edges,\n",
    "    num_nodes=num_nodes,\n",
    "    num_neg_samples=val_pos_edges.size(1)\n",
    ")\n",
    "val_data.edge_label_index = torch.cat([val_pos_edges, val_neg_edges], dim=-1)\n",
    "val_data.edge_label = torch.cat([torch.ones(val_pos_edges.size(1)), torch.zeros(val_neg_edges.size(1))], dim=0)\n",
    "\n",
    "# For the test set\n",
    "test_neg_edges = negative_sampling(\n",
    "    edge_index=all_pos_edges,\n",
    "    num_nodes=num_nodes,\n",
    "    num_neg_samples=test_pos_edges.size(1)\n",
    ")\n",
    "test_data.edge_label_index = torch.cat([test_pos_edges, test_neg_edges], dim=-1)\n",
    "test_data.edge_label = torch.cat([torch.ones(test_pos_edges.size(1)), torch.zeros(test_neg_edges.size(1))], dim=0)\n",
    "\n",
    "\n",
    "print(\"\\nData split and labeled successfully:\")\n",
    "print(\"\\n--- Training Data ---\")\n",
    "print(train_data)\n",
    "print(\"Edge labels shape:\", train_data.edge_label.shape)\n",
    "print(\"Edge label index shape:\", train_data.edge_label_index.shape)\n",
    "\n",
    "print(\"\\n--- Validation Data ---\")\n",
    "print(val_data)\n",
    "print(\"Edge labels shape:\", val_data.edge_label.shape)\n",
    "print(\"Edge label index shape:\", val_data.edge_label_index.shape)\n",
    "\n",
    "print(\"\\n--- Testing Data ---\")\n",
    "print(test_data)\n",
    "print(\"Edge labels shape:\", test_data.edge_label.shape)\n",
    "print(\"Edge label index shape:\", test_data.edge_label_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e726ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cpu\n",
      "\n",
      "GNN Encoder and Link Classifier models defined.\n"
     ]
    }
   ],
   "source": [
    "# Define GNN Encoder and Link Prediction Classifier\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    \"\"\"GNN to learn node embeddings.\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class LinkClassifier(torch.nn.Module):\n",
    "    \"\"\"Classifier to predict edge probability from node embeddings.\"\"\"\n",
    "    def forward(self, z, edge_label_index):\n",
    "        # z: node embeddings [num_nodes, embedding_dim]\n",
    "        # edge_label_index: edges to predict [2, num_edges_to_predict]\n",
    "        edge_feat_src = z[edge_label_index[0]]\n",
    "        edge_feat_dst = z[edge_label_index[1]]\n",
    "        # Simple dot product as a score\n",
    "        return (edge_feat_src * edge_feat_dst).sum(dim=-1)\n",
    "\n",
    "# Initialize the models\n",
    "encoder = GNNEncoder(data.num_node_features, HIDDEN_CHANNELS, EMBEDDING_DIM)\n",
    "classifier = LinkClassifier()\n",
    "\n",
    "# Move models to device if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "encoder = encoder.to(device)\n",
    "classifier = classifier.to(device)\n",
    "data = data.to(device)\n",
    "train_data, val_data, test_data = train_data.to(device), val_data.to(device), test_data.to(device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(classifier.parameters()), lr=0.01\n",
    ")\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(\"\\nGNN Encoder and Link Classifier models defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1694aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting GNN Training for Link Prediction ---\n",
      "✨ New best validation AUC: 0.3108\n",
      "✨ New best validation AUC: 0.3856\n",
      "✨ New best validation AUC: 0.7375\n",
      "✨ New best validation AUC: 0.7514\n",
      "Epoch: 010, Loss: 0.8071, Val AUC: 0.5494, Test AUC: 0.5481\n",
      "Epoch: 020, Loss: 0.6609, Val AUC: 0.7058, Test AUC: 0.7026\n",
      "✨ New best validation AUC: 0.7767\n",
      "✨ New best validation AUC: 0.8081\n",
      "✨ New best validation AUC: 0.8329\n",
      "✨ New best validation AUC: 0.8478\n",
      "✨ New best validation AUC: 0.8529\n",
      "Epoch: 030, Loss: 0.5822, Val AUC: 0.8268, Test AUC: 0.8214\n",
      "✨ New best validation AUC: 0.8536\n",
      "✨ New best validation AUC: 0.8638\n",
      "✨ New best validation AUC: 0.8733\n",
      "✨ New best validation AUC: 0.8817\n",
      "✨ New best validation AUC: 0.8877\n",
      "✨ New best validation AUC: 0.8910\n",
      "✨ New best validation AUC: 0.8918\n",
      "Epoch: 040, Loss: 0.5576, Val AUC: 0.8918, Test AUC: 0.8873\n",
      "✨ New best validation AUC: 0.8921\n",
      "✨ New best validation AUC: 0.8972\n",
      "✨ New best validation AUC: 0.9014\n",
      "✨ New best validation AUC: 0.9036\n",
      "✨ New best validation AUC: 0.9045\n",
      "Epoch: 050, Loss: 0.5479, Val AUC: 0.9034, Test AUC: 0.8999\n",
      "✨ New best validation AUC: 0.9064\n",
      "✨ New best validation AUC: 0.9092\n",
      "✨ New best validation AUC: 0.9109\n",
      "✨ New best validation AUC: 0.9114\n",
      "Epoch: 060, Loss: 0.5413, Val AUC: 0.9107, Test AUC: 0.9077\n",
      "Epoch: 070, Loss: 0.5370, Val AUC: 0.9097, Test AUC: 0.9073\n",
      "Epoch: 080, Loss: 0.5343, Val AUC: 0.9090, Test AUC: 0.9065\n",
      "Epoch: 090, Loss: 0.5321, Val AUC: 0.9082, Test AUC: 0.9056\n",
      "Epoch: 100, Loss: 0.5303, Val AUC: 0.9051, Test AUC: 0.9022\n",
      "Epoch: 110, Loss: 0.5288, Val AUC: 0.9020, Test AUC: 0.8989\n",
      "Epoch: 120, Loss: 0.5274, Val AUC: 0.8986, Test AUC: 0.8951\n",
      "Epoch: 130, Loss: 0.5263, Val AUC: 0.8975, Test AUC: 0.8935\n",
      "Epoch: 140, Loss: 0.5253, Val AUC: 0.8957, Test AUC: 0.8916\n",
      "Epoch: 150, Loss: 0.5244, Val AUC: 0.8933, Test AUC: 0.8895\n",
      "Epoch: 160, Loss: 0.5236, Val AUC: 0.8943, Test AUC: 0.8902\n",
      "Epoch: 170, Loss: 0.5228, Val AUC: 0.8924, Test AUC: 0.8884\n",
      "Epoch: 180, Loss: 0.5223, Val AUC: 0.8919, Test AUC: 0.8877\n",
      "Epoch: 190, Loss: 0.5215, Val AUC: 0.8900, Test AUC: 0.8859\n",
      "Epoch: 200, Loss: 0.5208, Val AUC: 0.8890, Test AUC: 0.8846\n",
      "--- GNN Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "# Training Loop and Evaluation Function\n",
    "\n",
    "def train():\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Use all edges from the original graph for message passing\n",
    "    z = encoder(train_data.x, train_data.edge_index)\n",
    "    \n",
    "    # Predict on the edges in the training set (positive and negative)\n",
    "    out = classifier(z, train_data.edge_label_index)\n",
    "    \n",
    "    loss = criterion(out, train_data.edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data_split):\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    # Generate embeddings using message passing edges\n",
    "    z = encoder(data_split.x, data_split.edge_index)\n",
    "    \n",
    "    # Predict on the edges in the validation/test set\n",
    "    out = classifier(z, data_split.edge_label_index)\n",
    "    \n",
    "    # Use AUC as the evaluation metric\n",
    "    return roc_auc_score(data_split.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "# --- Training ---\n",
    "print(\"\\n--- Starting GNN Training for Link Prediction ---\")\n",
    "best_val_auc = 0\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    \n",
    "    # Simple early stopping logic\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        print(f\"✨ New best validation AUC: {val_auc:.4f}\")\n",
    "        # Optionally save the best model\n",
    "        # torch.save(encoder.state_dict(), 'best_gnn_encoder.pt')\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Val AUC: {val_auc:.4f}, Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "print(\"--- GNN Training Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
