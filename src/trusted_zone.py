# Goal: Assess and clean data using defined quality rules for accurate downstream use.

# Tools: PySpark (SQL, DataFrame API), Delta Lake.

# Actions: Filter invalid values, impute missing data, remove duplicates, and write cleaned data to Trusted Zone.